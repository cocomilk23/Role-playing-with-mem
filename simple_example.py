#!/usr/bin/env python3
"""
ç®€æ´æ˜“æ‡‚çš„è§’è‰²æ‰®æ¼”æ™ºèƒ½ä½“ç¤ºä¾‹
åŠŸèƒ½ï¼šä¸“ä¸šè®°å¿†æ£€ç´¢ + å¯¹è¯è®°å¿† + LLMç”Ÿæˆå›å¤
ä½œè€…ï¼šåŸºäºRole-playing-with-memé¡¹ç›®
"""

import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from agent import RolePlayingAgent
from role import Role, create_default_role_config
from llm.connector import OpenAIConnector, MockLLMConnector
from memory.rag_utils import index_documents_to_chroma

class SimpleHealthAssistant:
    """ç®€åŒ–çš„å¥åº·åŠ©æ‰‹ç±»"""
    
    def __init__(self, use_openai=True):
        """
        åˆå§‹åŒ–å¥åº·åŠ©æ‰‹
        
        Args:
            use_openai: æ˜¯å¦ä½¿ç”¨OpenAI APIï¼ŒFalseåˆ™ä½¿ç”¨æ¨¡æ‹Ÿå™¨
        """
        self.project_root = os.path.dirname(os.path.abspath(__file__))
        self.setup_environment()
        self.agent = self.create_agent(use_openai)
        
    def setup_environment(self):
        """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
        # åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•
        os.chdir(self.project_root)
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        os.makedirs('data/memory_store', exist_ok=True)
        os.makedirs('data/chroma_db', exist_ok=True)
        os.makedirs('config/roles', exist_ok=True)
        
        # ç´¢å¼•ä¸“ä¸šçŸ¥è¯†åˆ°å‘é‡æ•°æ®åº“
        self.index_knowledge()
        
    def index_knowledge(self):
        """ç´¢å¼•åŒ»ç–—çŸ¥è¯†åˆ°ChromaDB"""
        knowledge_file = os.path.join(self.project_root, 'data/medical_knowledge.txt')
        
        if os.path.exists(knowledge_file):
            print("ğŸ“š æ­£åœ¨ç´¢å¼•åŒ»ç–—çŸ¥è¯†åº“...")
            index_documents_to_chroma(
                file_path=knowledge_file,
                collection_name="medical_knowledge_index_v1",
                db_path=os.path.join(self.project_root, 'data/chroma_db')
            )
            print("âœ… çŸ¥è¯†åº“ç´¢å¼•å®Œæˆ")
        else:
            print(f"âš ï¸  çŸ¥è¯†æ–‡ä»¶ä¸å­˜åœ¨: {knowledge_file}")
    
    def create_agent(self, use_openai=True):
        """åˆ›å»ºæ™ºèƒ½ä½“"""
        # 1. åˆ›å»ºè§’è‰²é…ç½®
        config_path = os.path.join(self.project_root, 'config/roles/health_assistant.json')
        create_default_role_config(config_path)
        
        # 2. åŠ è½½è§’è‰²
        role = Role.from_config(config_path)
        
        # 3. é€‰æ‹©LLMè¿æ¥å™¨
        if use_openai and os.getenv('OPENAI_API_KEY'):
            try:
                llm_connector = OpenAIConnector(
                    model_name="gpt-4o-mini",
                    base_url="https://hk.uniapi.io/v1"
                )
                print("ğŸ¤– ä½¿ç”¨ OpenAI GPT-4o-mini")
            except Exception as e:
                print(f"âš ï¸  OpenAIè¿æ¥å¤±è´¥: {e}")
                llm_connector = MockLLMConnector()
                print("ğŸ¤– ä½¿ç”¨æ¨¡æ‹Ÿè¿æ¥å™¨")
        else:
            llm_connector = MockLLMConnector()
            print("ğŸ¤– ä½¿ç”¨æ¨¡æ‹Ÿè¿æ¥å™¨")
        
        # 4. åˆ›å»ºæ™ºèƒ½ä½“
        agent = RolePlayingAgent(
            user_id="demo_user",
            role=role,
            llm_connector=llm_connector
        )
        
        print(f"âœ… æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
        print(f"   è§’è‰²: {role.name}")
        print(f"   æ¨¡å‹: {llm_connector.model_name}")
        
        return agent
    
    def chat(self, message: str) -> str:
        """
        ä¸æ™ºèƒ½ä½“å¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            æ™ºèƒ½ä½“å›å¤
        """
        return self.agent.process_query(message)
    
    def show_memory_status(self):
        """æ˜¾ç¤ºè®°å¿†çŠ¶æ€"""
        print("\nğŸ“‹ è®°å¿†çŠ¶æ€:")
        
        # å¯¹è¯è®°å¿†
        dialogue_count = len(self.agent.memory_manager.dialogue_memory.messages)
        print(f"   å¯¹è¯è®°å½•: {dialogue_count} æ¡")
        
        # ä¸“ä¸šè®°å¿†
        if self.agent.role.professional_knowledge_path:
            print(f"   ä¸“ä¸šçŸ¥è¯†åº“: {self.agent.role.professional_knowledge_path}")
        
        # è®°å¿†æ–‡ä»¶
        memory_path = f"data/memory_store/{self.agent.role.role_id}"
        if os.path.exists(memory_path):
            files = os.listdir(memory_path)
            print(f"   æŒä¹…åŒ–æ–‡ä»¶: {len(files)} ä¸ª")


def start_chat():
    """ç›´æ¥å¯åŠ¨èŠå¤©æ¨¡å¼"""
    print("ğŸ¥ å¥åº·åŠ©æ‰‹ - æ™ºèƒ½å¯¹è¯")
    print("=" * 40)
    
    # æ£€æŸ¥API Key
    use_openai = bool(os.getenv('OPENAI_API_KEY'))
    if not use_openai:
        print("ğŸ’¡ æç¤º: è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡å¯ä½¿ç”¨çœŸå®AIæ¨¡å‹")
    
    # åˆå§‹åŒ–åŠ©æ‰‹
    assistant = SimpleHealthAssistant(use_openai=use_openai)
    
    # ç›´æ¥è¿›å…¥äº¤äº’æ¨¡å¼
    print("\nğŸ’¬ å¼€å§‹å¯¹è¯ (è¾“å…¥ 'quit' é€€å‡º)")
    print("=" * 40)
    
    while True:
        try:
            user_input = input("\nğŸ‘¤ æ‚¨: ").strip()
            if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                break
            if not user_input:
                continue
                
            response = assistant.chat(user_input)
            print(f"ğŸ¤– åŠ©æ‰‹: {response}")
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"âŒ é”™è¯¯: {e}")
    
    print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨å¥åº·åŠ©æ‰‹ï¼")


if __name__ == '__main__':
    try:
        start_chat()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()